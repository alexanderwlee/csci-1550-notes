\documentclass{amsart}

\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{hyperref}

\newtheorem*{definition}{Definition}
\newtheorem*{theorem}{Theorem}
\newtheorem*{lemma}{Lemma}
\newtheorem*{corollary}{Corollary}
\newtheorem*{axiom}{Axiom}

\DeclarePairedDelimiter\abs{\lvert}{\rvert} % absolute value
% Swap the definition of \abs*, so that \abs
% resizes the size of the bars, and the starred version does not.
\makeatletter
\let\oldabs\abs%
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
\makeatother

\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\st}{\mathrel{:}}

\title{CSCI 2540: Probabilistic Methods in Computer Science (Notes)}
\author{Alexander Lee}

\begin{document}

\maketitle

\section*{1. Events and Probability}

\subsection*{1.2. Axioms of Probability}

\begin{definition}
  A probability space has three components:
  \begin{enumerate}
    \item a sample space $\Omega$, which is the set of all possible outcomes of
      the random process modeled by the probability space;
    \item a family of sets $\mathcal{F}$ representing the allowable events,
      where each set in $\mathcal{F}$ is a subset of the sample space $\Omega$;
      and
    \item a probability function $\Pr: \mathcal{F} \to \R$ satisfying the
      following definition.
  \end{enumerate}
\end{definition}

\begin{definition}
  A probability function is any function $\Pr: \mathcal{F} \to \R$ that
  satisfies the following conditions:
  \begin{enumerate}
    \item for any event $E$, $0 \leq \Pr(E) \leq 1$;
    \item $\Pr(\Omega) = 1$; and
    \item for any finite or countably infinite sequence of pairwise mutually
      disjoint events $E_1, E_2, E_3, \ldots$,
      \[
        \Pr \left( \bigcup_{i \geq 1} E_i \right) = \sum_{i \geq 1} \Pr(E_i).
      \]
  \end{enumerate}
\end{definition}

\begin{lemma}
  For any two events $E_1$ and $E_2$,
  \[
    \Pr(E_1 \cup E_2) = \Pr(E_1) + \Pr(E_2) - \Pr(E_1 \cap E_2).
  \]
\end{lemma}

\begin{lemma}[Union Bound]
  For any finite or countably infinite sequence of events $E_1, E_2, \ldots$,
  \[
    \Pr \left( \bigcup_{i \geq 1} E_i \right) \leq \sum_{i \geq 1} \Pr(E_i).
  \]
\end{lemma}

\begin{lemma}[1.3]
  Let $E_1, \ldots, E_n$ be any $n$ events. Then
  \begin{align*}
    \Pr \left( \bigcup_{i = 1}^n E_i \right) = & \sum_{i = 1}^n \Pr(E_i) - \sum_{i
    < j} \Pr(E_i \cap E_j) + \sum_{i < j < k} \Pr(E_i \cap E_j \cap E_k) \\
    &- \cdots + {(-1)}^{l + 1} \sum_{i_1 < i_2 < \cdots < i_l} \Pr \left(
    \bigcap_{r = 1}^l E_{i_r} \right) + \cdots.
  \end{align*}
\end{lemma}

\begin{definition}
  Two events $E$ and $F$ are independent if and only if
  \[
    \Pr(E \cap F) = \Pr(E) \cdot \Pr(F).
  \]
  More generally, events $E_1, E_2, \ldots, E_k$ are mutually independent if and
  only if, for any subset $I \subseteq [1, k]$,
  \[
    \Pr \left( \bigcap_{i \in I} E_i \right) = \prod_{i \in I} \Pr(E_i).
  \]
\end{definition}

\begin{definition}
  The conditional probability that event $E$ occurs given that event $F$ occurs
  is
  \[
    \Pr(E \mid F) = \frac{\Pr(E \cap F)}{\Pr(F)}.
  \]
  The conditional probability is well-defined only if $\Pr(F) > 0$.
\end{definition}

\begin{theorem}[Law of Total Probability]
  Let $E_1, E_2, \ldots, E_n$ be mutually disjoint events in the sample space
  $\Omega$, and let $\bigcup_{i = 1}^n E_i = \Omega$. Then
  \[
    \Pr(B) = \sum_{i = 1}^n \Pr(B \cap E_i) = \sum_{i = 1}^n \Pr(B \mid E_i)
    \Pr(E_i).
  \]
\end{theorem}

\begin{theorem}[Bayes' Law]
  Assume that $E_1, E_2, \ldots, E_n$ are mutually disjoint events in the sample
  space $\Omega$ such that $\bigcup_{i = 1}^n E_i = \Omega$. Then
  \[
    \Pr(E_j \mid B) = \frac{\Pr(E_j \cap B)}{\Pr(B)} = \frac{\Pr(B \mid E_j)
    \Pr(E_j)}{\sum_{i = 1}^n \Pr(B \mid E_i) \Pr(E_i)}.
  \]
\end{theorem}

\end{document}
